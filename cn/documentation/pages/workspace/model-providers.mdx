---
title: "模型供应商"
icon: "brain-arrow-curved-right"
---

<Note> ⚠️ 本文档由 AI 自动翻译。如有任何不准确之处，请参考[英文原版](/en/documentation/pages/workspace/model-providers)。</Note>


模型供应商为你的工作区提供AI模型访问。你构建的每个应用程序都需要模型才能运行，在工作区级别配置供应商意味着所有团队成员都可以在所有项目中使用它们。

## 系统供应商 vs 自定义供应商

**系统供应商**由Dify管理。你无需设置即可立即访问模型，通过Dify订阅计费，并在新模型可用时自动更新。最适合快速入门。

**自定义供应商**使用你自己的API密钥直接访问模型供应商，如OpenAI、Anthropic或Google。你获得完全控制权、直接计费，通常还有更高的速率限制。最适合生产应用程序。

你可以同时使用两种方式——系统供应商用于原型设计，自定义供应商用于生产。

## 配置自定义供应商

只有工作区管理员和所有者才能配置模型供应商。整个过程在各供应商之间是一致的：

<Steps>
  <Step title="导航至设置 → 模型供应商">
    在工作区设置中访问模型供应商配置。
  </Step>
  
  <Step title="选择你的供应商">
    从OpenAI、Anthropic、Google、Cohere或其他支持的供应商中选择。
  </Step>
  
  <Step title="添加凭据">
    输入你的API密钥和供应商要求的任何其他配置。
  </Step>
  
  <Step title="测试并保存">
    Dify在使供应商对你的工作区可用之前会验证你的凭据。
  </Step>
</Steps>

## 支持的供应商

**大型语言模型：**
- OpenAI (GPT-4, GPT-3.5-turbo)
- Anthropic (Claude)  
- Google (Gemini)
- Cohere
- 通过Ollama的本地模型

**文本嵌入模型：**
- OpenAI Embeddings
- Cohere Embeddings
- Azure OpenAI
- 本地文本嵌入模型

**专用模型：**
- 图像生成 (DALL-E, Stable Diffusion)
- 语音 (Whisper, ElevenLabs)
- 内容审核API

## 供应商配置示例

<Tabs>
  <Tab title="OpenAI">
    **必需：**来自OpenAI平台的API密钥
    
    **可选：**用于Azure OpenAI或代理的自定义基础URL，用于组织范围使用的组织ID
    
    **可用模型：**GPT-4、GPT-3.5-turbo、DALL-E、Whisper、文本嵌入
  </Tab>
  
  <Tab title="Anthropic">
    **必需：**来自Anthropic控制台的API密钥
    
    **可用模型：**Claude 3 (Opus, Sonnet, Haiku)、Claude 2.1、Claude Instant
  </Tab>
  
  <Tab title="本地 (Ollama)">
    **必需：**Ollama服务器URL（通常为http://localhost:11434）
    
    **设置：**安装Ollama，拉取模型（`ollama pull llama2`），配置Dify连接
    
    **优势：**完全数据隐私，无外部API成本，自定义模型微调
  </Tab>
</Tabs>

## 访问和计费

系统供应商通过你的Dify订阅计费，使用限制基于你的计划。自定义供应商直接通过供应商（OpenAI、Anthropic等）向你收费，通常提供更高的速率限制。

团队访问遵循工作区权限：
- **所有者/管理员**可以配置、修改和删除供应商
- **编辑者/成员**可以查看可用供应商并在应用程序中使用它们

<Warning>
API密钥安全存储但授予工作区范围的模型访问权限。只将管理权限授予应承担计费责任的可信团队成员。
</Warning>

## 故障排除

**身份验证失败：**验证API密钥准确性，检查过期时间，确保有足够积分，确认密钥权限。

**模型不可用：**检查供应商配置是否包含该模型，验证API密钥等级访问权限，刷新供应商设置。

**速率限制：**升级供应商账户，实施请求队列，考虑使用自定义供应商获得更高限制。
