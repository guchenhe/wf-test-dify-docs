---
title: "Knowledge Retrieval"
description: "Search knowledge bases for relevant information"
icon: "database"
---

The Knowledge Retrieval node searches your knowledge bases for relevant information and returns contextual content for use in downstream nodes. It enables RAG (Retrieval-Augmented Generation) applications by providing specific information from your documents.

<Frame caption="Knowledge Retrieval node configuration">
  <img src="https://assets-docs.dify.ai/dify-enterprise-mintlify/en/guides/workflow/node/d90961c6d794d425a8e11df177315188.png" alt="Knowledge Retrieval Node Interface" />
</Frame>

<Info>
  Create and populate knowledge bases before using this node. See the [knowledge base creation guide](/en/documentation/pages/knowledge/create-knowledge/introduction) for setup instructions.
</Info>

## Configuration

### Query and Knowledge Base Selection

The **Query** determines what to search for in your knowledge bases. Use `sys.query` for user input in chatflow applications, or any text variable from your workflow. Queries are limited to 200 characters.

Select one or more **Knowledge Bases** to search. Each contains indexed documents you've uploaded to Dify. Multiple knowledge bases can be searched simultaneously using different strategies.

### Retrieval Strategy

Choose how to search your content:

<Tabs>
  <Tab title="Semantic Search">
    Uses vector embeddings to find conceptually similar content based on meaning. Works well for natural language queries and related concepts with different terminology.
  </Tab>
  
  <Tab title="Keyword Search">
    Traditional full-text search for exact word matches. Faster and more predictable for specific terms, codes, or names.
  </Tab>
  
  <Tab title="Hybrid Search">
    Combines semantic and keyword approaches. Results are reranked using a specialized model for better relevance.
  </Tab>
</Tabs>

## Advanced Settings

<Frame caption="Advanced retrieval configuration options">
  <img src="https://assets-docs.dify.ai/2025/03/fbd43d558f83b355a1b18ac26a253b84.png" alt="Knowledge retrieval configuration interface" />
</Frame>

### Retrieval Parameters

**Top K** controls how many document chunks to retrieve. Start with 3-5 chunks for focused results or 10-15 for comprehensive coverage.

**Score Threshold** sets minimum similarity scores. Higher thresholds (0.7+) ensure relevance, lower thresholds (0.5-) include more tangential content.

**Reranking** re-scores results after initial retrieval. Enable for hybrid search, many chunks, or when precision matters more than speed.

### Metadata Filtering

Filter results using document metadata like type, date, or department. Set up metadata when uploading documents to enable targeted searching in large knowledge bases.

### Multi-Knowledge Base Strategies

**N-to-1 Recall** uses function calling to analyze queries, select appropriate knowledge bases, and optimize searches. Best for specialized knowledge bases in different domains.

**Multi-way Recall** queries all selected knowledge bases simultaneously and combines results. Use when information spans multiple sources or you need comprehensive coverage.

<Frame caption="Comparison of retrieval strategies for multiple knowledge bases">
  <img src="https://assets-docs.dify.ai/dify-enterprise-mintlify/en/guides/workflow/node/4a3007cda9dfa50ddac3711693725dce.png" alt="Retrieval Mode Comparison" />
</Frame>

## Output and Integration

The node outputs an array of retrieved document chunks containing text content and metadata (source, score, document ID). This structured output preserves information needed for citations.

### RAG Integration

Connect Knowledge Retrieval output to LLM node context inputs for RAG applications. When using retrieval results as context variables, Dify automatically tracks sources and enables citations.

```text
System: Answer based on the provided context.
Context: {{knowledge_retrieval.result}}
User: {{user_question}}
```

### Rate Limiting

Knowledge retrieval operations are subject to rate limits based on your subscription plan. The system tracks requests using Redis with a 60-second sliding window. When limits are exceeded, a `RateLimitExceeded` error is returned.

### Performance Considerations

Retrieval quality depends on indexing practices. Smaller chunks (200-500 tokens) enable precise retrieval, larger chunks (800-1500 tokens) maintain context. Knowledge bases have rate limits - the node handles throttling and caches identical queries automatically.
