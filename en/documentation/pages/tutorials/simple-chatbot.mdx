---
title: "Simple Chatbot"
description: "Hello World"
---

The real value of Dify lies in how easily you can build, deploy, and scale an idea no matter how complex. It's built for fast prototyping, smooth iteration, and reliable deployment at any level.

Let's start by learning reliable LLM integration into your applications. In this guide, you'll build a simple chatbot that classifies the user's question, respond directly using the LLM, and enhance the response with a country-specific fun fact.

<iframe 
  className="w-full aspect-video rounded-xl" 
  src="https://www.youtube.com/embed/dJ34OU_JY7Y?si=AiYJq7WY1iUCgGAO" 
  title="Dify Quick Start Video" 
  frameBorder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
  allowFullScreen 
/>

## Step 1: Create a New Workflow (2 min)

1. Go to **Studio** > **Workflow** > **Create from Blank** > **Orchestrate** > **New Chatflow** > **Create**

## Step 2: Add Workflow Nodes (6 min)

<Tip>
  When you want to reference any variable, type `{` or `/` first and you can see the different variables available in your workflow.
</Tip>

### 1. LLM Node and Output: Understand and Answer the Question

<Info>
  `LLM` node sends a prompt to a language model to generate a response based on user input. It abstracts away the complexity of API calls, rate limits, and infrastructure, so you can just focus on designing logic.
</Info>

<Steps>
  <Step title="Create LLM Node">
    Create an LLM node using the `Add Node` button and connect it to your Start node
  </Step>
  
  <Step title="Configure Model">
    Choose a default model
  </Step>
  
  <Step title="Set System Prompt">
    Paste this into the System Prompt field:

    ```text
    The user will ask a question about a country. The question is {{sys.query}}  
    Tasks: 
    1. Identify the country mentioned. 
    2. Rephrase the question clearly. 
    3. Answer the question using general knowledge. 
    
    Respond in the following JSON format: 
    {   
      "country": "<country name>",
      "question": "<rephrased question>",
      "answer": "<direct answer to the question>" 
    }
    ```
  </Step>
  
  <Step title="Enable Structured Output">
    **Enable Structured Output** allows you to easily control what the LLM will return and ensure consistent, machine-readable outputs for downstream use in precise data extraction or conditional logic.
    
    - Toggle Output Variables Structured ON > `Configure` and click `Import from JSON`
    - Paste:
    
    ```json
    {   
      "country": "string",   
      "question": "string",   
      "answer": "string" 
    }
    ```
  </Step>
</Steps>

### 2. Code Block: Get Fun Fact

<Info>
  `Code` node executes custom logic using code. It lets you inject code exactly where needed—within a visual workflow—saving you from wiring up an entire backend.
</Info>

<Steps>
  <Step title="Create Code Node">
    Create a `Code` Node using the `Add Node` button and connect to LLM block
  </Step>
  
  <Step title="Configure Input Variable">
    Change one `Input Variable` name to "country" and set the variable to `structured_output` > `country`
  </Step>
  
  <Step title="Add Python Code">
    Paste this code into `PYTHON3`:

    ```python
    def main(country: str) -> dict:     
      country_name = country.lower()     
      fun_facts = {
        "japan": "Japan has more than 5 million vending machines.",
        "france": "France is the most visited country in the world.",
        "italy": "Italy has more UNESCO World Heritage sites than any other country."     
      }     
      fun_fact = fun_facts.get(country_name, f"No fun fact available for {country.title()}.")
      return {"fun_fact": fun_fact}
    ```
  </Step>
  
  <Step title="Rename Output Variable">
    Change output variable `result` to `fun_fact` to have a better labeled variable
  </Step>
</Steps>

### 3. Answer Node: Final Answer to User

<Info>
  `Answer` Node creates a clean final output to return.
</Info>

<Steps>
  <Step title="Create Answer Node">
    Create an `Answer` Node using the `Add Node` button
  </Step>
  
  <Step title="Configure Answer Field">
    Paste into the Answer Field:

    ```text
    Q: {{ structured_output.question }} 

    A: {{ structured_output.answer }} 

    Fun Fact: {{ fun_fact }}
    ```
  </Step>
</Steps>

End Workflow:

<img
  src="/images/quick-start-workflow-overview.png"
  alt="Complete workflow diagram showing LLM, Code, and Answer nodes connected"
  style={{ width: "100%" }}
/>

---

## Step 3: Test the Bot (3 min)

Click `Preview`, then ask:

- "What is the capital of France?"
- "Tell me about Japanese cuisine"
- "Describe the culture in Italy"
- Any other questions

Make sure your Bot works as expected!

## You've Completed the Bot!

This guide showed how to integrate language models reliably and scalably without reinventing infrastructure. With Dify's visual workflows and modular nodes, you're not just building faster, you're adopting a clean, production-ready architecture for LLM-powered apps.
