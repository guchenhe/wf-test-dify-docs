---
title: "Model Providers"
description: "Configure AI model access for your workspace—the foundation that powers all your applications"
icon: "brain-arrow-curved-right"
---

Model providers give your workspace access to AI models. Every application you build needs models to function, and configuring providers at the workspace level means all team members can use them across all projects.

## System vs Custom Providers

**System Providers** are managed by Dify. You get immediate access to models without setup, billing through your Dify subscription, and automatic updates when new models become available. Best for getting started quickly.

**Custom Providers** use your own API keys for direct access to model providers like OpenAI, Anthropic, or Google. You get full control, direct billing, and often higher rate limits. Best for production applications.

You can use both simultaneously—system providers for prototyping, custom providers for production.

## Configuring Custom Providers

Only workspace admins and owners can configure model providers. The process is consistent across providers:

<Steps>
  <Step title="Navigate to Settings → Model Providers">
    Access the model provider configuration in your workspace settings.
  </Step>
  
  <Step title="Select your provider">
    Choose from OpenAI, Anthropic, Google, Cohere, or other supported providers.
  </Step>
  
  <Step title="Add credentials">
    Enter your API key and any additional configuration required by the provider.
  </Step>
  
  <Step title="Test and save">
    Dify validates your credentials before making the provider available to your workspace.
  </Step>
</Steps>

## Supported Providers

**Large Language Models:**
- OpenAI (GPT-4, GPT-3.5-turbo)
- Anthropic (Claude)  
- Google (Gemini)
- Cohere
- Local models via Ollama

**Embedding Models:**
- OpenAI Embeddings
- Cohere Embeddings
- Azure OpenAI
- Local embedding models

**Specialized Models:**
- Image generation (DALL-E, Stable Diffusion)
- Speech (Whisper, ElevenLabs)
- Moderation APIs

## Provider Configuration Examples

<Tabs>
  <Tab title="OpenAI">
    **Required:** API Key from OpenAI Platform
    
    **Optional:** Custom base URL for Azure OpenAI or proxies, Organization ID for organization-scoped usage
    
    **Available Models:** GPT-4, GPT-3.5-turbo, DALL-E, Whisper, Text embeddings
  </Tab>
  
  <Tab title="Anthropic">
    **Required:** API Key from Anthropic Console
    
    **Available Models:** Claude 3 (Opus, Sonnet, Haiku), Claude 2.1, Claude Instant
  </Tab>
  
  <Tab title="Local (Ollama)">
    **Required:** Ollama server URL (typically http://localhost:11434)
    
    **Setup:** Install Ollama, pull models (`ollama pull llama2`), configure Dify connection
    
    **Benefits:** Complete data privacy, no external API costs, custom model fine-tuning
  </Tab>
</Tabs>

## Access and Billing

System providers are billed through your Dify subscription with usage limits based on your plan. Custom providers bill you directly through the provider (OpenAI, Anthropic, etc.) and often provide higher rate limits.

Team access follows workspace permissions:
- **Owners/Admins** can configure, modify, and remove providers
- **Editors/Members** can view available providers and use them in applications

<Warning>
API keys are stored securely but grant workspace-wide model access. Only give admin privileges to trusted team members who should have billing responsibility.
</Warning>

## Troubleshooting

**Authentication Failed:** Verify API key accuracy, check expiration, ensure sufficient credits, confirm key permissions.

**Model Not Available:** Check provider configuration includes the model, verify API key tier access, refresh provider settings.

**Rate Limits:** Upgrade provider account, implement request queuing, consider custom providers for higher limits.

---

[Edit this page](https://github.com/langgenius/dify-docs/edit/main/en/guides/workspace/model-providers.mdx) | [Report an issue](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)
