---
title: "30分間クイックスタート"
description: "サンプルアプリを通じてDifyを深く理解"
icon: "forward"
---

<Note> ⚠️ このドキュメントはAIによって自動翻訳されています。不正確な部分がある場合は、[英語版](/en/use-dify/getting-started/quick-start)を参照してください。</Note>

このステップバイステップのチュートリアルでは、ゼロからマルチプラットフォームコンテンツジェネレーターを作成します。

基本的なLLM統合を超えて、強力なDifyノードを使用して、より速く、より簡単に洗練されたAIアプリケーションを構築する方法を発見します。

このチュートリアルの終わりまでに、あなたが投げかけるあらゆるコンテンツ（テキスト、ドキュメント、画像）を取り込み、好みの音声とトーンを追加し、選択した言語で洗練されたプラットフォーム固有のソーシャルメディア投稿を生成するワークフローを作成します。

完全なワークフローを以下に示します。構築中はいつでも参照して、軌道に乗っていることを確認し、すべてのノードがどのように連携するかを確認してください。

<img
  src="/images/deeper_dive_workflow_overview.png"
  alt="クイックスタートワークフロー概要"
  title="クイックスタートワークフロー概要"
  className="mx-auto"
/>

## ステップ1：新しいワークフローの作成

1. **スタジオ**に移動し、**空白から作成** \> **ワークフロー**を選択します。
2. ワークフローに`マルチプラットフォームコンテンツジェネレーター`という名前を付けて、**作成**をクリックします。自動的にワークフローキャンバスに移動し、構築を開始します。

## ステップ2：ワークフローノードの追加と設定

<Note>
  言及されていない設定はデフォルト値のままにしてください。
</Note>

<Tip>
  ノードと変数に明確で説明的な名前を付けて、ワークフロー内で識別と参照が簡単になるようにします。
</Tip>

### 1. ユーザー入力ノード：ユーザー入力を収集

<Info>
  まず、ドラフトテキスト、ターゲットプラットフォーム、希望のトーン、参考資料など、ユーザーから収集する情報を定義する必要があります。

  ユーザー入力ノードは、これらを簡単に設定できる場所です。ここに追加する各入力フィールドは、すべての下流ノードが参照して使用できる変数になります。
</Info>

<img
  src="/images/deeper_dive_start.png"
  alt="ユーザー入力ノード"
  title="ユーザー入力ノード"
  className="mx-auto"
  style={{ width:"71%" }}
/>

ユーザー入力ノードをクリックして設定パネルを開き、次の入力フィールドを追加します。

<Accordion title="参考資料 - テキスト">
  - フィールドタイプ：`段落`
  - 変数名：`draft`
  - ラベル名：`ドラフト`
  - 最大長：`2048`
  - 必須：`いいえ`
</Accordion>

<Accordion title="参考資料 - ファイル">
  - フィールドタイプ：`ファイルリスト`
  - 変数名：`user_file`
  - ラベル名：`ファイルをアップロード (≤ 10)`
  - サポートファイルタイプ：`ドキュメント`、`画像`
  - アップロードファイルタイプ：`両方`
  - 最大アップロード数：`10`
  - 必須：`いいえ`
</Accordion>

<Accordion title="ボイスとトーン">
  - フィールドタイプ：`段落`
  - 変数名：`voice_and_tone`
  - ラベル名：`ボイス＆トーン`
  - 最大長：`2048`
  - 必須：`いいえ`
</Accordion>

<Accordion title="ターゲットプラットフォーム">
  - フィールドタイプ：`短いテキスト`
  - 変数名：`platform`
  - ラベル名：`ターゲットプラットフォーム (≤ 10)`
  - 最大長：`256`
  - 必須：`はい`
</Accordion>

<Accordion title="言語要件">
  - フィールドタイプ：`選択`
  - 変数名：`language`
  - ラベル名：`言語`
  - オプション：
    - `English`
    - `日本語`
    - `简体中文`
  - デフォルト値：`English`
  - 必須：`はい`
</Accordion>

### 2. パラメータ抽出器ノード：ターゲットプラットフォームの識別

<Info>
  プラットフォームフィールドは自由形式のテキスト入力を受け入れるため、ユーザーは様々な方法で入力する可能性があります：`x and linkedIn`、`post on Twitter and LinkedIn`、さらには`Twitter + LinkedIn please`など。しかし、下流ノードが確実に動作できる`["Twitter", "LinkedIn"]`のようなクリーンで構造化されたリストが必要です。

  これはパラメータ抽出器ノードの完璧な仕事です。LLMを使用してユーザーの自然言語を分析し、これらすべてのバリエーションを認識し、標準化された配列を出力します。
</Info>

<img
  src="/images/deeper_dive_paramater_extractor.png"
  alt="パラメータ抽出器"
  title="パラメータ抽出器"
  className="mx-auto"
  style={{ width:"73%" }}
/>

ユーザー入力ノードの後に、パラメータ抽出器ノードを追加して設定します：

1. モデルを選択します。
2. `User Input/platform`を入力変数として設定します。
3. 抽出パラメータを追加します：
   1. 名前：`platform`
   2. タイプ：`Array[String]`
   3. 説明：`Identify and extract the platform(s) for which the user wants to create tailored content.`
   4. 必須：`はい`
4. 指示フィールドに、LLMのパラメータ抽出をガイドする以下を貼り付けます：

   ```markdown INSTRUCTION
   # TASK DESCRIPTION
   Parse platform names from input and output as a JSON array.
   
   ## PROCESSING RULES
   - Support multiple delimiters: commas, semicolons, spaces, line breaks, "and", "&", "|", etc.
   - Standardize common platform name variants (twitter/X→Twitter, insta→Instagram, etc.)
   - Remove duplicates and invalid entries
   - Preserve unknown but reasonable platform names
   
   ## OUTPUT REQUIREMENTS
   - Success: ["Platform1", "Platform2"] 
   - No platforms found: [No platforms identified. Please enter a valid platform name.]
   
   ## EXAMPLES
   - Input: "twitter, linkedin" → ["Twitter", "LinkedIn"]
   - Input: "x and insta" → ["Twitter", "Instagram"]
   - Input: "invalid content" → [No platforms identified. Please enter a valid platform name.]
   ```

   <Check>
     無効な入力に対して特定のエラーメッセージを出力するようLLMに指示したことに注意してください。これは次のステップでワークフローの終了トリガーとして機能します。
   </Check>

### 3. IF/ELSEノード：プラットフォーム抽出結果の検証

<Info>
  ユーザーが`ohhhhhh`や`BookFace`のような無効なプラットフォーム名を入力した場合はどうなるでしょうか？無駄なコンテンツを生成するために時間とトークンを無駄にしたくありません。

  そのような場合、IF/ELSEノードを使用してワークフローを早期に停止する分岐を作成できます。パラメータ抽出器ノードからのエラーメッセージをチェックする条件を設定し、そのメッセージが検出された場合、ワークフローは直接出力ノードにルーティングされて終了します。
</Info>

<img
  src="/images/deeper_dive_if.png"
  alt="If条件"
  className="mx-auto"
  style={{ width:"80%" }}
  title="If条件"
/>

1. パラメータ抽出器ノードの後に、IF/ELSEノードを追加します。
2. IF/ELSEノードのパネルで、IF条件を定義します：

   **IF** `Parameter Extractor/platform` `contains` `No platforms identified. Please enter a valid platform name.`
3. IF/ELSEノードの後、IFブランチに出力ノードを追加します。
4. 出力ノードのパネルで、`Parameter Extractor/platform`を出力変数として設定します。

### 4. リスト演算子ノード：アップロードされたファイルをタイプ別に分離

<Info>
  ユーザーは参考資料として画像とドキュメントの両方をアップロードできますが、この2つのタイプは異なる処理が必要です：画像はビジョン対応モデルで直接解釈できますが、ドキュメントはまずLLMがコンテンツを理解できるようにテキストに変換する必要があります。

  これを管理するために、2つのリスト演算子ノードを使用して、アップロードされたファイルをフィルタリングし、別々のブランチに分割します—1つは画像用、1つはドキュメント用です。
</Info>

<img
  src="/images/deeper_dive_list_operator.png"
  alt="リスト演算子"
  className="mx-auto"
  style={{ width:"70%" }}
  title="リスト演算子"
/>

1. IF/ELSEノードの後、ELSEブランチに2つのリスト演算子ノードを追加します。
2. 1つのノードを`Image`、もう1つを`Document`に名前を変更します。
3. 画像ノードを設定します：
   1. `User Input/user_file`を入力変数として設定します。
   2. フィルタ条件を有効にします：`{x}type` `in` `Image`
4. ドキュメントノードを設定します：
   1. `User Input/user_file`を入力変数として設定します。
   2. フィルタ条件を有効にします：`{x}type` `in` `Doc`。

### 5. ドキュメント抽出器ノード：ドキュメントからテキストを抽出

<Info>
  LLMはPDFやDOCXなどのアップロードされたファイルを直接読むことはできません。これらのドキュメントの情報を使用するには、まずLLMが処理できるプレーンテキストに変換する必要があります。

  これがまさにドキュメント抽出器ノードが行うことです。ドキュメントファイルを入力として受け取り、次のステップのためにクリーンで使用可能なテキストを出力します。
</Info>

1. ドキュメントノードの後に、ドキュメント抽出器ノードを追加します。
2. ドキュメント抽出器ノードのパネルで、`Document/result`を入力変数として設定します。

### 6. LLMノード：すべての参考資料を統合

<Info>
  ユーザーが複数の参考タイプ—ドラフトテキスト、ドキュメント、画像—を同時に提供する場合、それらを一つのまとまった要約に統合する必要があります。

  LLMノードは、すべての散在する部分を分析してこのタスクを処理し、後続のコンテンツ生成をガイドする包括的なコンテキストを作成します。
</Info>

<img
  src="/images/deeper_dive_info_integrate.png"
  alt="情報統合"
  className="mx-auto"
  style={{ width:"78%" }}
  title="情報統合"
/>

1. ドキュメント抽出器ノードの後に、LLMノードを追加します。
2. 画像ノードもこのLLMノードに接続します。
3. LLMノードをクリックして設定します：
   1. `Integrate Info`に名前を変更します。
   2. ビジョンをサポートするモデル（目のアイコンで示される）を選択します。
   3. **VISION**を有効にし、`Image/result`をビジョン変数として設定します。
   4. システムプロンプトフィールドに、以下を貼り付けます：

      <Warning>
        プロンプトで、_PROVIDED MATERIALS_の`Doc Extractor/text`と`User Input/draft`変数を参照するには、`{`または`/`を入力してリストから選択します。

        <img
          src="/images/deeper_dive_reference_variable.png"
          alt="変数を参照"
          title="変数を参照"
          className="mx-auto"
          style={{ width:"58%" }}
        />
      </Warning>
      ```markdown SYSTEM {2,3}
      # PROVIDED MATERIALS
      Doc Extractor/text
      User Input/draft
      
      # ROLE & TASK
      You are a content strategist. Analyze the provided materials and create a comprehensive content foundation for multi-platform social media optimization.
      
      # ANALYSIS PRINCIPLES
      - Work exclusively with provided information—no external assumptions
      - Focus on extraction, synthesis, and strategic interpretation
      - Identify compelling and actionable elements
      - Prepare insights adaptable across different platforms
      
      # REQUIRED ANALYSIS
      Deliver structured analysis with:
      
      ## 1. CORE MESSAGE
      - Central theme, purpose, objective
      - Key value or benefit being communicated
      
      ## 2. ESSENTIAL CONTENT ELEMENTS
      - Primary topics, facts, statistics, data points
      - Notable quotes, testimonials, key statements
      - Features, benefits, characteristics mentioned
      - Dates, locations, contextual details
      
      ## 3. STRATEGIC INSIGHTS
      - What makes content compelling/unique
      - Emotional/rational appeals present
      - Credibility factors, proof points
      - Competitive advantages highlighted
      
      ## 4. ENGAGEMENT OPPORTUNITIES
      - Discussion points, questions emerging
      - Calls-to-action, next steps suggested
      - Interactive/participation opportunities
      - Trending themes touched upon
      
      ## 5. PLATFORM OPTIMIZATION FOUNDATION
      - High-impact: Quick, shareable formats
      - Professional: Business-focused discussions
      - Community: Interaction and sharing
      - Visual: Enhanced with strong visuals
      
      ## 6. SUPPORTING DETAILS
      - Metrics, numbers, quantifiable results
      - Direct quotes, testimonials
      - Technical details, specifications
      - Background context available
      ```

### 7. イテレーションノード：各プラットフォーム向けにカスタマイズされたコンテンツを作成

<Info>
  統合された参照とターゲットプラットフォームの準備ができたので、イテレーションノードを使用して各プラットフォーム向けにカスタマイズされた投稿を生成しましょう。

  このノードはプラットフォームのリストをループし、各プラットフォーム用のサブワークフローを実行します：まず特定のプラットフォームのスタイルガイドラインとベストプラクティスを分析し、次に利用可能なすべての情報に基づいて最適化されたコンテンツを生成します。
</Info>

<img
  src="/images/deeper_dive_integration.png"
  alt="イテレーションノード"
  className="mx-auto"
  style={{ width:"62%" }}
  title="イテレーションノード"
/>

1. Integrate Infoノードの後に、イテレーションノードを追加します。
2. イテレーションノード内に、LLMノードを追加して設定します：
   1. `Identify Style`に名前を変更します。
   2. モデルを選択します。
   3. システムプロンプトフィールドに、以下を貼り付けます：

      <Warning>
        プロンプトで、_ROLE & TASK_と_OUTPUT FORMAT EXAMPLES_で`Current Iteration/item`変数を参照するには、`{`または`/`を入力してリストから選択します。
      </Warning>
      ````markdown SYSTEM {2,40}
      # ROLE & TASK
      You are a social media expert. Analyze the platform "Current Iteration/item" and provide content creation guidelines.
      
      # ANALYSIS REQUIRED
      For the given platform, provide:
      
      ## 1. PLATFORM PROFILE
      - Platform type and category
      - Target audience characteristics
      
      ## 2. CONTENT GUIDELINES
      - Optimal content length (characters/words)
      - Recommended tone (professional/casual/conversational)
      - Formatting best practices (line breaks, emojis, etc.)
      
      ## 3. ENGAGEMENT STRATEGY
      - Hashtag recommendations (quantity and style)
      - Call-to-action best practices
      - Algorithm optimization tips
      
      ## 4. TECHNICAL SPECS
      - Character/word limits
      - Visual content requirements
      - Special formatting needs
      
      ## 5. PLATFORM-SPECIFIC NOTES
      - Unique features or recent changes
      - Industry-specific considerations
      - Community engagement approaches
      
      # OUTPUT REQUIREMENTS
      - For recognized platforms: Provide specific guidelines
      - For unknown platforms: Base recommendations on similar platforms
      - Focus on actionable, practical advice
      - Be concise but comprehensive
      
      # OUTPUT FORMAT EXAMPLES
      ```json  
      {  
        "platform_name": "Current Iteration/item",  
        "platform_type": "social_media/professional_network/visual_platform/microblogging",  
        "content_guidelines": {  
          "max_length": "character/word limit",  
          "optimal_length": "recommended range",  
          "tone": "professional/casual/conversational/authoritative",  
          "hashtag_strategy": "quantity and placement guidelines",  
          "formatting": "line breaks, emojis, mentions guidelines",  
          "engagement_focus": "comments/shares/likes/retweets",  
          "call_to_action": "appropriate CTA style"  
        },  
        "special_considerations": "Any unique platform requirements or recent changes",  
        "confidence_level": "high/medium/low based on platform recognition"  
      }
      ````
3. Identify Styleノードの後に、別のLLMノードを追加して設定します：
   1. `Create Content`に名前を変更します。
   2. モデルを選択します。
   3. システムプロンプトフィールドに、以下を貼り付けます：

      <Warning>
        プロンプトで、以下の変数を参照するには、`{`または`/`を入力してリストから選択します。
        - _PLATFORM GUIDELINES_の`Identify Style/text`
        - _SOURCE INFORMATION_の`Integrate Info/text`
        - _VOICE & TONE (OPTIONAL)_の`User Input/voice_and_tone`
        - _LANGUAGE REQUIREMENT_の`User Input/language`
      </Warning>
      ```markdown SYSTEM {6,9,12,15}
      # ROLE & TASK
      You are an expert social media content creator. Generate publication-ready content that matches platform guidelines, incorporates source information, and follows specified voice/tone and language requirements.
      
      # INPUT MATERIALS
      ## 1. PLATFORM GUIDELINES
      Identify Style/text
      
      ## 2. SOURCE INFORMATION
      Integrate Info/text
      
      ## 3. VOICE & TONE (OPTIONAL)
      User Input/voice_and_tone
      
      ## 4. LANGUAGE REQUIREMENT
      - Generate ALL content exclusively in: User Input/language
      - No mixing of languages whatsoever
      - Adapt platform terminology to the specified language
      
      # CONTENT REQUIREMENTS
      - Follow platform guidelines exactly (format, length, tone, hashtags)
      - Integrate source information effectively (key messages, data, value props)
      - Apply voice & tone consistently (if provided)
      - Optimize for platform-specific engagement
      - Ensure cultural appropriateness for the specified language
      
      # OUTPUT FORMAT
      - Generate ONLY the final social media post content. No explanations or meta-commentary. Content must be immediately copy-paste ready.
      - Maximum heading level: ## (H2) - never use # (H1)
      - No horizontal dividers: avoid ---
      
      # QUALITY CHECKLIST
      ✅ Platform guidelines followed
      ✅ Source information integrated  
      ✅ Voice/tone consistent (when provided)
      ✅ Language consistency maintained
      ✅ Engagement optimized
      ✅ Publication ready
      ```
   4. 構造化出力を有効にします。

      <img
        src="/images/deeper_dive_structured_output.png"
        alt="構造化出力"
        title="構造化出力"
        className="mx-auto"
        style={{ width:"64%" }}
      />
      1. **OUTPUT VARIABLES**の横で、**STRUCTURED**をオンに切り替えます。structured_output変数が下に表示されます。
      2. **structured_output**の横で、**Configure**をクリックします。
      3. ポップアップスキーマエディタで、右上隅の**Import From JSON**をクリックし、以下を貼り付けます：

         ```json
         {   
           "platform_name": "string",
           "post_content": "string"   
         }
         ```
4. イテレーションノードをクリックして設定します：
   1. `Parameter Extractor/platform`を入力変数として設定します。
   2. `Create Content/structured_output`を出力変数として設定します。
   3. **PARALLEL MODE**を有効にし、最大並列性を`10`に設定します。

      <Check>
        これが、ユーザー入力ノードのターゲットプラットフォームフィールドのラベル名に`(≤10)`を含めた理由です。
      </Check>

### 8. テンプレートノード：最終出力をフォーマット

<Info>
  イテレーションノードは各プラットフォーム用の投稿を生成しますが、その出力は生のデータ配列（例：`[{"platform_name": "Twitter", "post_content": "..."}]`）であり、あまり読みやすくありません。結果をより明確な形式で提示する必要があります。

  ここでテンプレートノードが登場します—[Jinja2](https://jinja.palletsprojects.com/en/stable/)テンプレートを使用してこの生データを整理されたテキストにフォーマットでき、最終出力がユーザーフレンドリーで理解しやすいことを保証します。
</Info>

<img
  src="/images/deeper_dive_template.png"
  alt="テンプレートノード"
  title="テンプレートノード"
  style={{ width:"49%" }}
  className="mx-auto"
/>

1. イテレーションノードの後に、テンプレートノードを追加します。
2. テンプレートノードのパネルで、`Iteration/output`を入力変数として設定します。
3. 以下のJinja2コードを貼り付けます（**コメントを削除することを忘れずに**）。

   ```
   {% for item in output %}        # Loop through each platform-content pair in the input array
   # 📱 {{ item.platform_name }}   # Display the platform name as an H1 heading with a phone emoji
   {{ item.post_content }}        # Display the generated content for this platform
                                  # Add a blank line between platforms for better readability
   {% endfor %}                   # End the loop
   ```

   <Tip>
     LLMも出力フォーマットを処理できますが、その出力は一貫性がなく予測不可能な場合があります。推論を必要としないルールベースのフォーマットについては、テンプレートノードがゼロトークンコストでより安定した信頼性の高い方法で処理します。

     LLMは非常に強力ですが、適切なツールを使用するタイミングを知ることが、より信頼性が高くコスト効果の高いAIアプリケーションを構築する鍵です。
   </Tip>

### 9. 出力ノード：結果をユーザーに返す

1. テンプレートノードの後に、出力ノードを追加します。
2. 出力ノードのパネルで、`Template/output`を出力変数として設定します。

## ステップ3：テスト

ワークフローが完成しました！テストしてみましょう。

1. チェックリストがクリアされていることを確認します。

   <img
     src="/images/deeper_dive_checklist_clear.png"
     alt="チェックリストを確認"
     className="mx-auto"
     style={{ width:"77%" }}
     title="チェックリストを確認"
   />
2. 最初に提供された参照図と照らし合わせてワークフローを確認し、すべてのノードと接続が一致していることを確認します。
3. 右上隅の**Test Run**をクリックし、入力フィールドを入力して、**Start Run**をクリックします。

   キャッシュされた入力で単一のノードを実行するには、その設定パネルの上部にある**Run this step**アイコンをクリックします。

   <Tip>
     前のノードからの異なる入力に対するノードの反応をテストするには、ワークフロー全体を再実行する必要はありません。キャンバスの下部にある**View cached variables**をクリックし、リストから変更したい変数を見つけて、その値を編集するだけです。
   </Tip>
   エラーが発生した場合は、対応するノードの**LAST RUN**ログをチェックして、問題の正確な原因を特定します。

## ステップ4：公開と共有

ワークフローが期待通りに実行され、結果に満足したら、**Publish** \> **Publish Update**をクリックして、ライブで共有可能にします。

<Warning>
  後で変更を加えた場合は、更新が有効になるように必ず再度公開することを忘れないでください。
</Warning>

<Tip>
  公開後、ライブ環境でクイックなエンドツーエンドテストを実行して、すべてが**スタジオ**と同じように動作することを確認できます。
</Tip>

---

## 翻訳ワークフローに関する注記

このドキュメントは、リファクタリングされた翻訳システムをテストするために修正されました。システムは現在、`zh`/`ja`言語コード（`cn`/`jp`の代わりに）を使用し、全体を通じて設定駆動の言語参照を使用しています。この修正により、git diff分析を使用したコンテキスト認識翻訳がトリガーされるはずです。