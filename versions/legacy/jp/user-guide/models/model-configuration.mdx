---
title: モデル
version: '日本語'
---

Difyは大規模言語モデルに基づいたAIアプリケーション開発プラットフォームです。初めて使用する際には、Difyの**設定 -- モデルプロバイダー**ページで必要なモデルを追加および設定してください。

<Frame>
  <img src="https://assets-docs.dify.ai/2025/05/81a18a5999e20d5928c804ed71216989.png" alt="Settings - Model Provider" />
</Frame>

Difyは現在、OpenAIのGPTシリーズやAnthropicのClaudeシリーズなど、主流となっているモデルプロバイダーをサポートしています。各モデルの能力やパラメータの種類が異なるため、アプリケーションのニーズに応じた適切なモデルプロバイダーを選択できます。**Difyで以下のモデル能力を使用する前に、各モデルプロバイダーの公式サイトでAPIキーを取得する必要があります。**

### モデルタイプ

Difyでは、使用シーンに応じてモデルを4つのタイプに分類しています：

1.  **システム推論モデル**。アプリケーション内で使用されるのはこのタイプのモデルです。チャット、会話名生成、次の質問の提案でもこの推論モデルが使用されます。

    > サポートされているシステム推論モデルプロバイダー：[OpenAI](https://platform.openai.com/account/api-keys)、[Azure OpenAIサービス](https://azure.microsoft.com/en-us/products/ai-services/openai-service/)、[Anthropic](https://console.anthropic.com/account/keys)、Hugging Faceハブ、Replicate、Xinference、OpenLLM、[讯飞星火](https://www.xfyun.cn/solutions/xinghuoAPI)、[文心一言](https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)、[通义千问](https://dashscope.console.aliyun.com/api-key\_management?spm=a2c4g.11186623.0.0.3bbc424dxZms9k)、[Minimax](https://api.minimax.chat/user-center/basic-information/interface-key)、ZHIPU(ChatGLM)
2.  **Embedding モデル**。データセット内の分割された文書の埋め込みに使用されるのはこのタイプのモデルです。データセットを使用するアプリケーションでは、ユーザーの質問を埋め込み処理する際にもこのタイプのモデルが使用されます。

    > サポートされているEmbedding モデルプロバイダー：OpenAI、ZHIPU(ChatGLM)、Jina AI([Jina Embeddings](https://jina.ai/embeddings/))
3.  [**Rerankモデル**](../knowledge-base/indexing-and-retrieval/rerank)。**Rerankモデルは検索能力を強化し、LLMの検索結果を改善するために使用されます。**

    > サポートされているRerankモデルプロバイダー：Cohere、Jina AI([Jina Reranker](https://jina.ai/reranker))
4.  **音声からテキストへのモデル**。対話型アプリケーションで音声をテキストに変換する際に使用されるのはこのタイプのモデルです。

    > サポートされている音声からテキストへのモデルプロバイダー：OpenAI

技術の進化とユーザーのニーズに応じて、今後もさらに多くのLLMプロバイダーをサポートしていきます。

### ホストモデル試用サービス

Difyクラウドサービスのユーザーには、異なるモデルの無料利用枠を提供しています。無料利用枠の範囲を超えるとアプリケーションの正常な使用に影響を及ぼす可能性がありますのでその前に自分のモデルプロバイダーを設定してください。

* **OpenAIホストモデル試用：** GPT3.5-turbo、GPT3.5-turbo-16k、text-davinci-003モデルの試用として200回までの無料で呼び出すことが可能です。

### デフォルトモデルの設定

Difyは使用シーンに応じて設定されたデフォルトモデルを選択します。`設定 > モデルプロバイダー`でデフォルトモデルを設定します。

<Frame>
  <img src="https://assets-docs.dify.ai/2025/05/b21a962a799af0c186c499af3f2c2b06.png" alt="Default Model Settings" />
</Frame>

システム推論モデル：アプリケーションの作成に使用されるデフォルトの推論モデルを設定し、会話タイトルの生成や次のステップの質問に関する提案などの機能も含まれます。

### モデルの接続設定

Difyの`設定 > モデルプロバイダー`で接続するモデルを設定します。

<Frame>
  <img src="https://assets-docs.dify.ai/2025/05/056cb0de89831a1efbe574c72eec0355.png" alt="Model Integration Settings" />
</Frame>

モデルプロバイダーは2種類あります：

1. 自社モデル。このタイプのモデルプロバイダーは自社で開発したモデルを提供します。例としてOpenAI、Anthropicなどがあります。
2. ホストモデル。このタイプのモデルプロバイダーは第三者のモデルを提供します。例としてHugging Face、Replicateなどがあります。

Difyではそれぞれのタイプのモデルプロバイダーを接続するための設定方法を用意しています。

**自社モデルのモデルプロバイダーの接続**

自社モデルのプロバイダーを接続すると、Difyはそのプロバイダーのすべてのモデルに自動的に接続します。

Difyで対応するモデルプロバイダーのAPIキーを設定するだけで、そのモデルプロバイダーに接続できます。

<Note>
    Difyは[PKCS1_OAEP](https://pycryptodome.readthedocs.io/en/latest/src/cipher/oaep.html)を使用してユーザーが管理するAPIキーを暗号化して保存しています。各テナントは独立したキーペアを使用して暗号化しているので、APIキーの漏洩を防ぐことができます。
</Note>

### モデルの使用

モデルの設定が完了したら、アプリケーションでこれらのモデルを使用できます：

<Frame>
  <img src="https://assets-docs.dify.ai/2025/05/4d227cd3bb4f4d21a4c5f6a080843701.png" alt="Using Models in Application" />
</Frame>
